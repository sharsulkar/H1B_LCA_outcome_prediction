{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_sh_make_observations_file.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIb2UNR1b6jqkYg0n+Ij9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharsulkar/H1B_LCA_outcome_prediction/blob/main/prototyping/notebooks/02_sh_make_observations_file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnB_fiAUHX57"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QDxdkiPHmdp"
      },
      "source": [
        "def read_csv_to_list(filepath, header=None, squeeze=True):\r\n",
        "    \"\"\"\r\n",
        "        Read a CSV file into a list.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            filepath (str): CSV file path\r\n",
        "            header (int, list of int, optional): Row number(s) to use as the column names, and the start of the data. Defaults to None.\r\n",
        "            squeeze (bool, optional): If the parsed data only contains one column then return a Series. Defaults to True.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            list: list of values from CSV file\r\n",
        "        \"\"\"\r\n",
        "    return list(pd.read_csv(filepath, header=None, squeeze=True))\r\n",
        "\r\n",
        "def modify_observations(df,index,columns,values,modify_action='update_values'):\r\n",
        "  #assert - index, columns and values are string list type, \r\n",
        "  #columns and values are same size, for single column - value should be scalar\r\n",
        "  #columns that have modification exist in observation_df\r\n",
        "  #\r\n",
        "  if modify_action=='add_row':\r\n",
        "    df.loc[index]=values\r\n",
        "\r\n",
        "  elif modify_action=='update_values':\r\n",
        "    df.loc[index,columns]=values\r\n",
        "  \r\n",
        "  return df\r\n",
        "\r\n",
        "def missing_statistics(df,column):\r\n",
        "  return (df.shape[0]-df[column].count())*100/df.shape[0]\r\n",
        "\r\n",
        "def cardinality_statistics(df,column):\r\n",
        "  return (df.shape[0]-len(df[column].unique()))*100/df.shape[0]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAaeUtT9Hl0Z"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "\r\n",
        "class DropRowsTransformer(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\"\r\n",
        "    A class to drop rows from a DataFrame.\r\n",
        "\r\n",
        "    Args:\r\n",
        "        row_index (pandas index object) : A list of indexes that should be dropped from the DataFrame.\r\n",
        "        inplace : x (default=True)\r\n",
        "        reset_index : binary (default=True)\r\n",
        "            Whether reindexing should be performed after drop action\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, row_index, inplace, reset_index):\r\n",
        "        \"\"\"\r\n",
        "        Constructs all the necessary attributes for the DropRowsTransformer object.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            row_index : pandas index object\r\n",
        "                A list of indexes that should be dropped from the DataFrame.\r\n",
        "            inplace : binary (default=True)\r\n",
        "                Whether the action should be performed inplace or not\r\n",
        "            reset_index : binary (default=True)\r\n",
        "                Whether reindexing should be performed after drop action\r\n",
        "        \"\"\"\r\n",
        "        self.row_index = row_index\r\n",
        "        self.inplace = True\r\n",
        "        self.reset_index = True\r\n",
        "\r\n",
        "    def fit(self, X, y=None):\r\n",
        "        \"\"\"\r\n",
        "        Fit the class on input dataframe\r\n",
        "\r\n",
        "        Args:\r\n",
        "            X (pandas DataFrame): input dataframe\r\n",
        "            y : place holder, defaulted to None\r\n",
        "        \"\"\"\r\n",
        "        return self\r\n",
        "\r\n",
        "    def transform(self, X, y=None):\r\n",
        "        \"\"\"\r\n",
        "        Apply transforms on the input dataframe\r\n",
        "\r\n",
        "        Args:\r\n",
        "            X (pandas DataFrame): input dataframe\r\n",
        "            y : place holder, defaulted to None\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            X : Transformed dataframe\r\n",
        "        \"\"\"\r\n",
        "        X.drop(index=self.row_index, inplace=self.inplace)\r\n",
        "        if self.reset_index:\r\n",
        "            X.reset_index(inplace=True)\r\n",
        "        return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUSDoHnrIDxZ"
      },
      "source": [
        "class BuildFeaturesTransformer(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\"\r\n",
        "    A class to build new features. \r\n",
        "\r\n",
        "    Args:\r\n",
        "        input_columns (array or list) : The columns that will be used as input for building new features.\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        DataFrame : Transformed dataframe with new features added in as columns\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, input_columns):\r\n",
        "        \"\"\"\r\n",
        "        Constructs all the necessary attributes for the BuildFeaturesTransformer object.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            input_columns (array or list) : The columns that will be used as input for building new features.\r\n",
        "        \"\"\"\r\n",
        "        self.input_columns = input_columns\r\n",
        "\r\n",
        "    def date_diff(self, date1, date2):\r\n",
        "        \"\"\"\r\n",
        "        Returns the difference between two input dates as timedelta.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            date1 (datetime): A date\r\n",
        "            date2 (datetime): Another date\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            date_difference (timedelta): difference between date1 and date2\r\n",
        "        \"\"\"\r\n",
        "        date_difference = date1-date2\r\n",
        "        return date_difference\r\n",
        "\r\n",
        "    def is_usa(self, country):\r\n",
        "        \"\"\"\r\n",
        "        Checks whether country is 'UNITED STATES OF AMERICA' or not and returns a binary flag\r\n",
        "\r\n",
        "        Args:\r\n",
        "            country (str): country\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            USA_YN (str): binary flag based on country value\r\n",
        "        \"\"\"\r\n",
        "        if country == 'UNITED STATES OF AMERICA':\r\n",
        "            USA_YN = 'Y'\r\n",
        "        else:\r\n",
        "            USA_YN = 'N'\r\n",
        "        return USA_YN\r\n",
        "\r\n",
        "    def fit(self, X, y=None):\r\n",
        "        \"\"\"\r\n",
        "        Fit the class on input dataframe\r\n",
        "\r\n",
        "        Args:\r\n",
        "            X (pandas DataFrame): input dataframe\r\n",
        "            y : place holder, defaulted to None\r\n",
        "        \"\"\"\r\n",
        "        return self\r\n",
        "\r\n",
        "    def transform(self, X, y=None):\r\n",
        "        \"\"\"\r\n",
        "        Apply transforms on the input dataframe to build new features\r\n",
        "\r\n",
        "        Args:\r\n",
        "            X (pandas DataFrame): input dataframe\r\n",
        "            y : place holder, defaulted to None\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            X : Transformed dataframe with new features added in as columns\r\n",
        "        \"\"\"\r\n",
        "        # Processing_Days and Validity_days\r\n",
        "        X['PROCESSING_DAYS'] = self.date_diff(X.DECISION_DATE, X.RECEIVED_DATE).dt.days\r\n",
        "        X['VALIDITY_DAYS'] = self.date_diff(X.END_DATE, X.BEGIN_DATE).dt.days\r\n",
        "\r\n",
        "        # SOC_Codes\r\n",
        "        X['SOC_CD2'] = X.SOC_CODE.str.split(pat='-', n=1, expand=True)[0]\r\n",
        "        X['SOC_CD4'] = X.SOC_CODE.str.split(pat='-', n=1, expand=True)[1].str.split(pat='.', n=1, expand=True)[0]\r\n",
        "        X['SOC_CD_ONET'] = X.SOC_CODE.str.split(pat='-', n=1, expand=True)[1].str.split(pat='.', n=1, expand=True)[1]\r\n",
        "\r\n",
        "        # USA_YN\r\n",
        "        X['USA_YN'] = X.EMPLOYER_COUNTRY.apply(self.is_usa)\r\n",
        "\r\n",
        "        # Employer_Worksite_YN\r\n",
        "        X['EMPLOYER_WORKSITE_YN'] = 'Y'\r\n",
        "        X.loc[X.EMPLOYER_POSTAL_CODE.ne(X.WORKSITE_POSTAL_CODE), 'EMPLOYER_WORKSITE_YN'] = 'N'\r\n",
        "\r\n",
        "        # OES_YN\r\n",
        "        X['OES_YN'] = 'Y'\r\n",
        "        X.iloc[X[~X.PW_OTHER_SOURCE.isna()].index,X.columns.get_loc('OES_YN')] = 'N'\r\n",
        "\r\n",
        "        # SURVEY_YEAR\r\n",
        "        X['SURVEY_YEAR'] = pd.to_datetime(X.PW_OES_YEAR.str.split(pat='-', n=1, expand=True)[0]).dt.to_period('Y')\r\n",
        "        pw_other_year = X[X.OES_YN == 'N'].PW_OTHER_YEAR\r\n",
        "        #Rename the series and update dataframe with series object\r\n",
        "        pw_other_year.rename(\"SURVEY_YEAR\", inplace=True)\r\n",
        "        X.update(pw_other_year)\r\n",
        "\r\n",
        "        # WAGE_ABOVE_PREVAILING_HR\r\n",
        "        X['WAGE_PER_HR'] = X.WAGE_RATE_OF_PAY_FROM\r\n",
        "        #compute for Year\r\n",
        "        X.iloc[X[X.WAGE_UNIT_OF_PAY == 'Year'].index, X.columns.get_loc('WAGE_PER_HR')] = X[X.WAGE_UNIT_OF_PAY == 'Year'].WAGE_RATE_OF_PAY_FROM/2067\r\n",
        "        #compute for Month\r\n",
        "        X.iloc[X[X.WAGE_UNIT_OF_PAY == 'Month'].index, X.columns.get_loc('WAGE_PER_HR')] = X[X.WAGE_UNIT_OF_PAY == 'Month'].WAGE_RATE_OF_PAY_FROM/172\r\n",
        "\r\n",
        "        #initialize with WAGE_RATE_OF_PAY_FROM\r\n",
        "        X['PW_WAGE_PER_HR'] = X.PREVAILING_WAGE\r\n",
        "        #compute for Year\r\n",
        "        X.iloc[X[X.PW_UNIT_OF_PAY == 'Year'].index, X.columns.get_loc('PW_WAGE_PER_HR')] = X[X.PW_UNIT_OF_PAY == 'Year'].PREVAILING_WAGE/2067\r\n",
        "        #compute for Month\r\n",
        "        X.iloc[X[X.PW_UNIT_OF_PAY == 'Month'].index, X.columns.get_loc('PW_WAGE_PER_HR')] = X[X.PW_UNIT_OF_PAY == 'Month'].PREVAILING_WAGE/172\r\n",
        "\r\n",
        "        X['WAGE_ABOVE_PW_HR'] = X.WAGE_PER_HR-X.PW_WAGE_PER_HR\r\n",
        "\r\n",
        "        return X\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgeB4ypnHg3R"
      },
      "source": [
        "#load data\r\n",
        "#required_features=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/required_features.csv',header=None,squeeze=True)\r\n",
        "input_df=pd.read_excel('https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/LCA_Disclosure_Data_FY2020_Q2.xlsx')"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQobzgoNIUCZ"
      },
      "source": [
        "#build features\r\n",
        "fe_cols=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/feature_engineering_columns.csv',header=None,squeeze=True)\r\n",
        "drop_row_index=input_df[~input_df.CASE_STATUS.isin(['Certified','Denied'])].index\r\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RISm9dU7IZXo"
      },
      "source": [
        "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
        "#Build preprocessing pipeline\r\n",
        "build_feature_pipe=make_pipeline(\r\n",
        "    DropRowsTransformer(row_index=drop_row_index,inplace=True,reset_index=True),\r\n",
        "    BuildFeaturesTransformer(fe_cols)\r\n",
        ")"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJinKUTBIcRx"
      },
      "source": [
        "transformed_df=build_feature_pipe.transform(input_df)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gmrCv_9I_TZ"
      },
      "source": [
        "observations_df=pd.DataFrame(data=None,\r\n",
        "                            index=transformed_df.columns,\r\n",
        "                            columns=['Dtype','percent_missing','cardinality','preprocess_action','preprocess_comment','new_feature_name','new_feature_logic','categorical_class','embedding']\r\n",
        ")"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ezNcAkJMMA"
      },
      "source": [
        "for column in transformed_df.columns:\r\n",
        "  #Fill in Dtype, missing and cardinality statistics\r\n",
        "  observations_df=modify_observations(df=observations_df,\r\n",
        "                                      index=column,\r\n",
        "                                      columns=['Dtype','percent_missing','cardinality'],\r\n",
        "                                      values=[transformed_df[column].dtype,missing_statistics(transformed_df,column),cardinality_statistics(transformed_df,column)],\r\n",
        "                                      modify_action='update_values')\r\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpFUu6v7Lwur"
      },
      "source": [
        "#drop features with missing values >threshold\r\n",
        "missing_threshold=40.0\r\n",
        "for idx in observations_df[observations_df.percent_missing>=missing_threshold].index:\r\n",
        "  observations_df=modify_observations(df=observations_df,\r\n",
        "                                      index=idx,\r\n",
        "                                      columns=['preprocess_action','preprocess_comment'],\r\n",
        "                                      values=['Drop column','missing values>='+str(missing_threshold)+'% of total'],\r\n",
        "                                      modify_action='update_values')\r\n",
        "  #observations_df.loc[[idx],['preprocess_action','preprocess_comment']]=['Drop column','missing values>='+str(missing_threshold)+'% of total']"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HwLcQNiMUj6"
      },
      "source": [
        "#drop features with cardinality>threshold\r\n",
        "cardinality_threshold=80.0\r\n",
        "for idx in observations_df[observations_df.cardinality<80.0].index:\r\n",
        "  observations_df=modify_observations(df=observations_df,\r\n",
        "                                      index=idx,\r\n",
        "                                      columns=['preprocess_action','preprocess_comment'],\r\n",
        "                                      values=['Drop column','High Cardinality, threshold '+str(cardinality_threshold)+'% of total'],\r\n",
        "                                      modify_action='update_values')"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnEkFEoxMyPI"
      },
      "source": [
        "#Separate target column\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index='CASE_STATUS',\r\n",
        "                                    columns=['preprocess_action','preprocess_comment'],\r\n",
        "                                    values=['Pop column into a separate list','Target feature'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['CASE_STATUS'],['preprocess_action','preprocess_comment']]=['Pop column into a separate list','Target feature']\r\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVu2W7SvNdVe"
      },
      "source": [
        "#FEATURE Engineering - date columns\r\n",
        "#Create a new feature - PROCESSING_DAYS from 'RECEIVED_DATE', 'DECISION_DATE'\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=['RECEIVED_DATE', 'DECISION_DATE'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','PROCESSING_DAYS','days(DECISION_DATE-RECEIVED_DATE)'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['RECEIVED_DATE', 'DECISION_DATE'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','PROCESSING_DAYS','days(DECISION_DATE-RECEIVED_DATE)']\r\n",
        "#Create a new feature - VALIDITY_DAYS from 'BEGIN_DATE', 'END_DATE'\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=['BEGIN_DATE', 'END_DATE'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','VALIDITY_DAYS','days(END_DATE-BEGIN_DATE)'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['BEGIN_DATE', 'END_DATE'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','VALIDITY_DAYS','days(END_DATE-BEGIN_DATE)']\r\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LrvZa8hOIto"
      },
      "source": [
        "#Feature engineering - split SOC_CODE into 2 new features - SOC_CODE_2, SOC_CODE_4\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index='SOC_CODE',\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','SOC_CODE_2,SOC_CODE_4','SOC_CODE.split(\\'-\\')'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['SOC_CODE'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','SOC_CODE_2,SOC_CODE_4','SOC_CODE.split(\\'-\\')']"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLig793oO-13"
      },
      "source": [
        "#Feature engineering - EMPLOYER_COUNTRY - US or NOT\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index='EMPLOYER_COUNTRY',\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','USA_YN','IF EMPLOYER_COUNTRY==USA THEN Y ELSE N END'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['EMPLOYER_COUNTRY'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','USA_YN','IF EMPLOYER_COUNTRY==USA THEN Y ELSE N END']"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCMJEiisPNNY"
      },
      "source": [
        "#Drop columns - EMPLOYER_* except 'EMPLOYER_NAME',EMPLOYER_POSTAL_CODE\r\n",
        "not_useful_cols=['TRADE_NAME_DBA','EMPLOYER_ADDRESS1','EMPLOYER_ADDRESS2','EMPLOYER_CITY','EMPLOYER_STATE',\r\n",
        "          'EMPLOYER_PROVINCE','EMPLOYER_PHONE','EMPLOYER_PHONE_EXT','EMPLOYER_POC_LAST_NAME',\r\n",
        "          'EMPLOYER_POC_FIRST_NAME','EMPLOYER_POC_MIDDLE_NAME','EMPLOYER_POC_JOB_TITLE','EMPLOYER_POC_ADDRESS1',\r\n",
        "          'EMPLOYER_POC_ADDRESS2','EMPLOYER_POC_CITY','EMPLOYER_POC_STATE','EMPLOYER_POC_POSTAL_CODE',\r\n",
        "          'EMPLOYER_POC_COUNTRY','EMPLOYER_POC_PROVINCE','EMPLOYER_POC_PHONE','EMPLOYER_POC_PHONE_EXT','EMPLOYER_POC_EMAIL',\r\n",
        "          'AGENT_ATTORNEY_LAST_NAME','AGENT_ATTORNEY_FIRST_NAME','AGENT_ATTORNEY_MIDDLE_NAME','AGENT_ATTORNEY_ADDRESS1',\r\n",
        "          'AGENT_ATTORNEY_ADDRESS2','AGENT_ATTORNEY_CITY','AGENT_ATTORNEY_STATE','AGENT_ATTORNEY_POSTAL_CODE',\r\n",
        "          'AGENT_ATTORNEY_COUNTRY','AGENT_ATTORNEY_PROVINCE','AGENT_ATTORNEY_PHONE','AGENT_ATTORNEY_PHONE_EXT',\r\n",
        "          'AGENT_ATTORNEY_EMAIL_ADDRESS','LAWFIRM_NAME_BUSINESS_NAME','STATE_OF_HIGHEST_COURT','NAME_OF_HIGHEST_STATE_COURT','SECONDARY_ENTITY_BUSINESS_NAME',\r\n",
        "          'WORKSITE_ADDRESS1','WORKSITE_ADDRESS2','WORKSITE_CITY','WORKSITE_COUNTY','WORKSITE_STATE','WAGE_UNIT_OF_PAY','PW_UNIT_OF_PAY','APPENDIX_A_ATTACHED','STATUTORY_BASIS']\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=not_useful_cols,\r\n",
        "                                    columns=['preprocess_action','preprocess_comment'],\r\n",
        "                                    values=['Drop column','Not Useful'],\r\n",
        "                                    modify_action='update_values')"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJTph8sCPUTX"
      },
      "source": [
        "#Feature engineering - Worksite same as employer address \r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=['WORKSITE_POSTAL_CODE','EMPLOYER_POSTAL_CODE'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','EMPLOYER_WORKSITE_YN','IF EMPLOYER_POSTAL_CODE==WORKSITE_POSTAL_CODE THEN Y ELSE N END'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['WORKSITE_POSTAL_CODE'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','EMPLOYER_WORKSITE_YN','IF EMPLOYER_POSTAL_CODE==WORKSITE_POSTAL_CODE THEN Y ELSE N END']\r\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY0hxtBhPWJH"
      },
      "source": [
        "\r\n",
        "#Feature engineering - convert PREVAILING_WAGE and WAGE_RATE_OF_PAY_FROM to hourly wage - if PW_UNIT_OF_PAY=Hour ignore, if Month then WAGE/172, if Year then WAGE/2067\r\n",
        "#Feature engineering - WAGE_ABOVE_PREVAILING_HR = WAGE_RATE_OF_PAY_FROM_HR-PREVAILING_WAGE_HR\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=['PREVAILING_WAGE','PW_UNIT_OF_PAY'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','PREVAILING_WAGE_HR;WAGE_ABOVE_PREVAILING_HR','if PW_UNIT_OF_PAY=Hour ignore, if Month then WAGE/172, if Year then WAGE/2067;WAGE_RATE_OF_PAY_FROM_HR-PREVAILING_WAGE_HR'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['PREVAILING_WAGE'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','PREVAILING_WAGE_HR;WAGE_ABOVE_PREVAILING_HR','if PW_UNIT_OF_PAY=Hour ignore, if Month then WAGE/172, if Year then WAGE/2067;WAGE_RATE_OF_PAY_FROM_HR-PREVAILING_WAGE_HR']\r\n",
        "\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=['WAGE_RATE_OF_PAY_FROM','WAGE_UNIT_OF_PAY'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','WAGE_RATE_OF_PAY_FROM_HR;WAGE_ABOVE_PREVAILING_HR','if WAGE_UNIT_OF_PAY=Hour ignore, if Month then WAGE/172, if Year then WAGE/2067;WAGE_RATE_OF_PAY_FROM_HR-PREVAILING_WAGE_HR'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['WAGE_RATE_OF_PAY_FROM'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','WAGE_RATE_OF_PAY_FROM_HR;WAGE_ABOVE_PREVAILING_HR','if WAGE_UNIT_OF_PAY=Hour ignore, if Month then WAGE/172, if Year then WAGE/2067;WAGE_RATE_OF_PAY_FROM_HR-PREVAILING_WAGE_HR']\r\n"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV6N91DtPalw"
      },
      "source": [
        "#Feature engineering - OES_YN - if 'PW_OTHER_SOURCE' is not NaN then N else Y\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index='PW_OTHER_SOURCE',\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','OES_YN ','if PW_OTHER_SOURCE is not NaN then N else Y'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['PW_OTHER_SOURCE'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','OES_YN ','if PW_OTHER_SOURCE is not NaN then N else Y']\r\n",
        "#Feature engineering - SURVEY_YEAR - if OES_YN ==Y then extract year from first date of PW_OES_YEAR' else 'PW_OTHER_YEAR'\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=['PW_OES_YEAR','PW_OTHER_YEAR'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic'],\r\n",
        "                                    values=['Drop column','Feature engineering','SURVEY_YEAR ','if OES_YN ==Y then extract year from first date of PW_OES_YEAR else PW_OTHER_YEAR'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[['PW_OES_YEAR','PW_OTHER_YEAR'],['preprocess_action','preprocess_comment','new_feature_name','new_feature_logic']]=['Drop column','Feature engineering','SURVEY_YEAR ','if OES_YN ==Y then extract year from first date of PW_OES_YEAR else PW_OTHER_YEAR']\r\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLJDQZfbPciX"
      },
      "source": [
        "#Categorical columns \r\n",
        "cat_cols=['CASE_STATUS','VISA_CLASS','SOC_CODE','SOC_TITLE','EMPLOYER_NAME','EMPLOYER_POSTAL_CODE','WORKSITE_POSTAL_CODE','PW_OTHER_SOURCE','PUBLIC_DISCLOSURE','NAICS_CODE','EMPLOYER_NAME']\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=cat_cols,\r\n",
        "                                    columns=['categorical_class', 'embedding'],\r\n",
        "                                    values=['Categorical','Standardized random'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[cat_cols,['categorical_class', 'embedding']]=['Categorical','Standardized random']"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjUw36NKPehW"
      },
      "source": [
        "#Ordinal columns\r\n",
        "ord_cols=['PW_WAGE_LEVEL','PW_OES_YEAR']\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=ord_cols,\r\n",
        "                                    columns=['categorical_class', 'embedding'],\r\n",
        "                                    values=['Ordinal','Ordered standardized random'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[ord_cols,['categorical_class', 'embedding']]=['Ordinal','Ordered standardized random']\r\n"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qIOyffdPgYm"
      },
      "source": [
        "#binary columns\r\n",
        "binary_cols=['FULL_TIME_POSITION','AGENT_REPRESENTING_EMPLOYER','SECONDARY_ENTITY','AGREE_TO_LC_STATEMENT','H-1B_DEPENDENT','WILLFUL_VIOLATOR','EMPLOYER_COUNTRY']\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=binary_cols,\r\n",
        "                                    columns=['categorical_class', 'embedding'],\r\n",
        "                                    values=['Binary','Standardized random'],\r\n",
        "                                    modify_action='update_values')\r\n",
        "#df_data_statistics.loc[binary_cols,['categorical_class', 'embedding']]=['Binary','Standardized random']\r\n"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9pbRr5qiT8V"
      },
      "source": [
        "numeric_cols=['TOTAL_WORKER_POSITIONS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT','CHANGE_PREVIOUS_EMPLOYMENT', 'NEW_CONCURRENT_EMPLOYMENT','CHANGE_EMPLOYER', 'AMENDED_PETITION', 'WORKSITE_WORKERS','TOTAL_WORKSITE_LOCATIONS']\r\n",
        "observations_df=modify_observations(df=observations_df,\r\n",
        "                                    index=numeric_cols,\r\n",
        "                                    columns=['categorical_class', 'embedding'],\r\n",
        "                                    values=['Numerical','Standard scaling'],\r\n",
        "                                    modify_action='update_values')\r\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9ghTOcCPh9_"
      },
      "source": [
        "#Update details for new features - Numeric\r\n",
        "observations_df=modify_observations(observations_df,\r\n",
        "                                    index=['PROCESSING_DAYS','VALIDITY_DAYS','WAGE_ABOVE_PW_HR'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','categorical_class','embedding'],\r\n",
        "                                    values=['New feature','Feature engineering','Numerical','Standard scaling'],\r\n",
        "                                    modify_action='update_values')"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XKKvdiqVVHy"
      },
      "source": [
        "##Update details for new features - Categorical\r\n",
        "observations_df=modify_observations(observations_df,\r\n",
        "                                    index=['SOC_CD2','SOC_CD4','SOC_CD_ONET'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','categorical_class','embedding'],\r\n",
        "                                    values=['New feature','Feature engineering','Categorical','Standardized random'],\r\n",
        "                                    modify_action='update_values')"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pppA8Rd2Wf-2"
      },
      "source": [
        "##Update details for new features - Binary\r\n",
        "observations_df=modify_observations(observations_df,\r\n",
        "                                    index=['USA_YN','EMPLOYER_WORKSITE_YN','OES_YN'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','categorical_class','embedding'],\r\n",
        "                                    values=['New feature','Feature engineering','Binary','Standardized random'],\r\n",
        "                                    modify_action='update_values')"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7BBlFWhWzHO"
      },
      "source": [
        "##Update details for new features - Ordinal\r\n",
        "observations_df=modify_observations(observations_df,\r\n",
        "                                    index=['SURVEY_YEAR'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment','categorical_class','embedding'],\r\n",
        "                                    values=['New feature','Feature engineering','Ordinal','Ordered standardized random'],\r\n",
        "                                    modify_action='update_values')"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPpS96oMXIMe"
      },
      "source": [
        "observations_df=modify_observations(observations_df,\r\n",
        "                                    index=['VISA_CLASS', 'SOC_TITLE', 'FULL_TIME_POSITION','TOTAL_WORKER_POSITIONS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT','CHANGE_PREVIOUS_EMPLOYMENT', 'NEW_CONCURRENT_EMPLOYMENT','CHANGE_EMPLOYER', 'AMENDED_PETITION', 'EMPLOYER_NAME', 'NAICS_CODE','AGENT_REPRESENTING_EMPLOYER', 'WORKSITE_WORKERS', 'SECONDARY_ENTITY','PW_WAGE_LEVEL', 'TOTAL_WORKSITE_LOCATIONS', 'AGREE_TO_LC_STATEMENT','H-1B_DEPENDENT', 'WILLFUL_VIOLATOR', 'PUBLIC_DISCLOSURE'],\r\n",
        "                                    columns=['preprocess_action','preprocess_comment'],\r\n",
        "                                    values=['Use feature as is','Use feature as is'],\r\n",
        "                                    modify_action='update_values')"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ig1mwvEnK0aB",
        "outputId": "3b63ad9e-ab25-44e6-addb-30a9d0060f35"
      },
      "source": [
        "observations_df"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dtype</th>\n",
              "      <th>percent_missing</th>\n",
              "      <th>cardinality</th>\n",
              "      <th>preprocess_action</th>\n",
              "      <th>preprocess_comment</th>\n",
              "      <th>new_feature_name</th>\n",
              "      <th>new_feature_logic</th>\n",
              "      <th>categorical_class</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Drop column</td>\n",
              "      <td>High Cardinality, threshold 80.0% of total</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CASE_NUMBER</th>\n",
              "      <td>object</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Drop column</td>\n",
              "      <td>High Cardinality, threshold 80.0% of total</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CASE_STATUS</th>\n",
              "      <td>object</td>\n",
              "      <td>0</td>\n",
              "      <td>99.9987</td>\n",
              "      <td>Pop column into a separate list</td>\n",
              "      <td>Target feature</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>Standardized random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RECEIVED_DATE</th>\n",
              "      <td>datetime64[ns]</td>\n",
              "      <td>0</td>\n",
              "      <td>99.9352</td>\n",
              "      <td>Drop column</td>\n",
              "      <td>Feature engineering</td>\n",
              "      <td>PROCESSING_DAYS</td>\n",
              "      <td>days(DECISION_DATE-RECEIVED_DATE)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DECISION_DATE</th>\n",
              "      <td>datetime64[ns]</td>\n",
              "      <td>0</td>\n",
              "      <td>99.9563</td>\n",
              "      <td>Drop column</td>\n",
              "      <td>Feature engineering</td>\n",
              "      <td>PROCESSING_DAYS</td>\n",
              "      <td>days(DECISION_DATE-RECEIVED_DATE)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OES_YN</th>\n",
              "      <td>object</td>\n",
              "      <td>0</td>\n",
              "      <td>99.9987</td>\n",
              "      <td>New feature</td>\n",
              "      <td>Feature engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Binary</td>\n",
              "      <td>Standardized random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SURVEY_YEAR</th>\n",
              "      <td>object</td>\n",
              "      <td>0.199739</td>\n",
              "      <td>99.9934</td>\n",
              "      <td>New feature</td>\n",
              "      <td>Feature engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ordinal</td>\n",
              "      <td>Ordered standardized random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WAGE_PER_HR</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>83.585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PW_WAGE_PER_HR</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>91.9985</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WAGE_ABOVE_PW_HR</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>69.8817</td>\n",
              "      <td>New feature</td>\n",
              "      <td>Feature engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Numerical</td>\n",
              "      <td>Standard scaling</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>109 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Dtype  ...                    embedding\n",
              "index                      int64  ...                          NaN\n",
              "CASE_NUMBER               object  ...                          NaN\n",
              "CASE_STATUS               object  ...          Standardized random\n",
              "RECEIVED_DATE     datetime64[ns]  ...                          NaN\n",
              "DECISION_DATE     datetime64[ns]  ...                          NaN\n",
              "...                          ...  ...                          ...\n",
              "OES_YN                    object  ...          Standardized random\n",
              "SURVEY_YEAR               object  ...  Ordered standardized random\n",
              "WAGE_PER_HR              float64  ...                          NaN\n",
              "PW_WAGE_PER_HR           float64  ...                          NaN\n",
              "WAGE_ABOVE_PW_HR         float64  ...             Standard scaling\n",
              "\n",
              "[109 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZJK2BKcc6ol"
      },
      "source": [
        "observations_df.to_csv('/content/drive/MyDrive/final_observations.csv',sep='$')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhUFBanmdXQO"
      },
      "source": [
        "required_features=list(observations_df[(observations_df.preprocess_comment.isin(['Feature engineering','Target feature','Use feature as is'])) & (~observations_df.preprocess_action.isin(['New feature']))].index)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LptfRWuVgEAl",
        "outputId": "09cac6e0-7048-407d-baff-42c32a6b80e9"
      },
      "source": [
        "set(required_features)-set(observations_df[observations_df.preprocess_action.isin([np.NaN,'New feature','Use feature as is'])].index.values)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BEGIN_DATE',\n",
              " 'CASE_STATUS',\n",
              " 'DECISION_DATE',\n",
              " 'EMPLOYER_COUNTRY',\n",
              " 'EMPLOYER_POSTAL_CODE',\n",
              " 'END_DATE',\n",
              " 'PREVAILING_WAGE',\n",
              " 'PW_OES_YEAR',\n",
              " 'PW_OTHER_SOURCE',\n",
              " 'PW_OTHER_YEAR',\n",
              " 'PW_UNIT_OF_PAY',\n",
              " 'RECEIVED_DATE',\n",
              " 'SOC_CODE',\n",
              " 'WAGE_RATE_OF_PAY_FROM',\n",
              " 'WAGE_UNIT_OF_PAY',\n",
              " 'WORKSITE_POSTAL_CODE'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    }
  ]
}