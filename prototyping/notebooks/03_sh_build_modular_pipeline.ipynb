{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_sh_build_modular_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/sharsulkar/H1B_LCA_outcome_prediction/blob/main/prototyping/notebooks/03_sh_build_modular_pipeline.ipynb",
      "authorship_tag": "ABX9TyMaalwfqbPVqtJBN5Axi+Wc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharsulkar/H1B_LCA_outcome_prediction/blob/main/prototyping/notebooks/03_sh_build_modular_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4lWGBZmT4tl"
      },
      "source": [
        "import numpy as np\r\n",
        "np.random.seed(42)\r\n",
        "import pandas as pd\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
        "from sklearn.compose import make_column_transformer\r\n",
        "from pickle import dump, load"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1zPOs-5UA1P"
      },
      "source": [
        "def read_csv_to_list(filepath,header=None,squeeze=True):\r\n",
        "  return list(pd.read_csv(filepath,header=None,squeeze=True))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71TscV2JUBWs"
      },
      "source": [
        "#Import Q1 and Q2 data into 2 separate dataframes \r\n",
        "required_features=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/required_features.csv',header=None,squeeze=True)\r\n",
        "\r\n",
        "data1_df=pd.read_excel('/content/drive/MyDrive/Datasets/H1B_LCA_prediction/LCA_Disclosure_Data_FY2020_Q1.xlsx',usecols=required_features)\r\n",
        "data1_dfcopy=data1_df.copy()\r\n",
        "\r\n",
        "data2_df=pd.read_excel('/content/drive/MyDrive/Datasets/H1B_LCA_prediction/LCA_Disclosure_Data_FY2020_Q2.xlsx',usecols=required_features)\r\n",
        "data2_dfcopy=data1_df.copy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91oQkbV_UfGv"
      },
      "source": [
        "#Import Q1 and Q2 data into single dataframe\r\n",
        "data_files_list_path='/content/drive/MyDrive/Datasets/LCA_files_list.txt'\r\n",
        "#create an empty dataframe to hold the final concatenated result\r\n",
        "input_df=pd.DataFrame(columns=required_features)\r\n",
        "\r\n",
        "#define the file object \r\n",
        "file_itr=open(file=data_files_list_path,mode='r')\r\n",
        "\r\n",
        "#iterate through the file and append the data to input_df\r\n",
        "for path in file_itr:\r\n",
        "  data_df=pd.read_excel(path,usecols=required_features)\r\n",
        "  input_df=input_df.append(data_df,ignore_index=True)    \r\n",
        "\r\n",
        "file_itr.close\r\n",
        "\r\n",
        "input_dfcopy=input_df.copy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ur5nciLUvJ4"
      },
      "source": [
        "#Custom transformer to drop rows based on filter\r\n",
        "class droprows_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self):\r\n",
        "      self.row_index = None # row index to drop\r\n",
        "      self.inplace=True\r\n",
        "      self.reset_index=True\r\n",
        "\r\n",
        "    def fit( self, X, y=None):\r\n",
        "      return self \r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "      self.row_index=X[~X.CASE_STATUS.isin(['Certified','Denied'])].index\r\n",
        "      X.drop(index=self.row_index,inplace=self.inplace)\r\n",
        "      if self.reset_index:\r\n",
        "        X.reset_index(inplace=True)#,drop=True\r\n",
        "      return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa7huR4QU67G"
      },
      "source": [
        "class buildfeatures_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "  def __init__(self, input_columns):\r\n",
        "    self.input_columns=input_columns\r\n",
        "\r\n",
        "  def date_diff(self,date1,date2):\r\n",
        "    return date1-date2\r\n",
        "\r\n",
        "  def is_USA(self,country):\r\n",
        "    if country=='UNITED STATES OF AMERICA':\r\n",
        "      USA_YN='Y' \r\n",
        "    else:\r\n",
        "      USA_YN='N'\r\n",
        "    return USA_YN\r\n",
        "\r\n",
        "  def fit(self, X, y=None):\r\n",
        "    return self\r\n",
        "\r\n",
        "  def transform(self, X, y=None):\r\n",
        "    # Processing_Days and Validity_days\r\n",
        "    X['PROCESSING_DAYS']=self.date_diff(X.DECISION_DATE, X.RECEIVED_DATE).dt.days\r\n",
        "    X['VALIDITY_DAYS']=self.date_diff(X.END_DATE, X.BEGIN_DATE).dt.days\r\n",
        "\r\n",
        "    # SOC_Codes\r\n",
        "    X['SOC_CD2']=X.SOC_CODE.str.split(pat='-',n=1,expand=True)[0]\r\n",
        "    X['SOC_CD4']=X.SOC_CODE.str.split(pat='-',n=1,expand=True)[1].str.split(pat='.',n=1,expand=True)[0]\r\n",
        "    X['SOC_CD_ONET']=X.SOC_CODE.str.split(pat='-',n=1,expand=True)[1].str.split(pat='.',n=1,expand=True)[1]\r\n",
        "\r\n",
        "    # USA_YN\r\n",
        "    X['USA_YN']=X.EMPLOYER_COUNTRY.apply(self.is_USA)\r\n",
        "\r\n",
        "    # Employer_Worksite_YN\r\n",
        "    X['EMPLOYER_WORKSITE_YN']='Y'\r\n",
        "    X.loc[X.EMPLOYER_POSTAL_CODE.ne(X.WORKSITE_POSTAL_CODE),'EMPLOYER_WORKSITE_YN']='N'\r\n",
        "\r\n",
        "    # OES_YN\r\n",
        "    X['OES_YN']='Y'\r\n",
        "    X.iloc[X[~X.PW_OTHER_SOURCE.isna()].index,X.columns.get_loc('OES_YN')]='N'\r\n",
        "\r\n",
        "    # SURVEY_YEAR\r\n",
        "    X['SURVEY_YEAR']=pd.to_datetime(X.PW_OES_YEAR.str.split(pat='-',n=1,expand=True)[0]).dt.to_period('Y')\r\n",
        "    PW_other_year=X[X.OES_YN=='N'].PW_OTHER_YEAR\r\n",
        "    #Rename the series and update dataframe with series object\r\n",
        "    PW_other_year.rename(\"SURVEY_YEAR\",inplace=True)\r\n",
        "    X.update(PW_other_year)\r\n",
        "\r\n",
        "    # WAGE_ABOVE_PREVAILING_HR\r\n",
        "    X['WAGE_PER_HR']=X.WAGE_RATE_OF_PAY_FROM\r\n",
        "    #compute for Year\r\n",
        "    X.iloc[X[X.WAGE_UNIT_OF_PAY=='Year'].index,X.columns.get_loc('WAGE_PER_HR')]=X[X.WAGE_UNIT_OF_PAY=='Year'].WAGE_RATE_OF_PAY_FROM/2067\r\n",
        "    #compute for Month\r\n",
        "    X.iloc[X[X.WAGE_UNIT_OF_PAY=='Month'].index,X.columns.get_loc('WAGE_PER_HR')]=X[X.WAGE_UNIT_OF_PAY=='Month'].WAGE_RATE_OF_PAY_FROM/172\r\n",
        "\r\n",
        "    #initialize with WAGE_RATE_OF_PAY_FROM\r\n",
        "    X['PW_WAGE_PER_HR']=X.PREVAILING_WAGE\r\n",
        "    #compute for Year\r\n",
        "    X.iloc[X[X.PW_UNIT_OF_PAY=='Year'].index,X.columns.get_loc('PW_WAGE_PER_HR')]=X[X.PW_UNIT_OF_PAY=='Year'].PREVAILING_WAGE/2067\r\n",
        "    #compute for Month\r\n",
        "    X.iloc[X[X.PW_UNIT_OF_PAY=='Month'].index,X.columns.get_loc('PW_WAGE_PER_HR')]=X[X.PW_UNIT_OF_PAY=='Month'].PREVAILING_WAGE/172\r\n",
        "\r\n",
        "    X['WAGE_ABOVE_PW_HR']=X.WAGE_PER_HR-X.PW_WAGE_PER_HR\r\n",
        "\r\n",
        "    return X"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdciQTOrVBW4"
      },
      "source": [
        "#Custom transformer to drop features for input feature list\r\n",
        "class dropfeatures_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, columns, inplace):\r\n",
        "      self.columns = columns # list of categorical columns in input Dataframe\r\n",
        "      self.inplace=True\r\n",
        "\r\n",
        "    def fit( self, X, y=None):\r\n",
        "      return self \r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "      X.drop(columns=self.columns,inplace=self.inplace)\r\n",
        "      return X"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbawNyXCVHrm"
      },
      "source": [
        "#Custom transformer to compute Random Standard encoding\r\n",
        "#add option to return ordered encoding, whether to include encoding for missing value or not\r\n",
        "class RSE_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "    #Class Constructor\r\n",
        "    def __init__( self, cat_cols, categories=None, RSE=None ):\r\n",
        "        self.cat_cols = cat_cols # list of categorical columns in input Dataframe\r\n",
        "        self.categories = categories # Array of unique non-numeric values in each categorical column\r\n",
        "        self.RSE = RSE # Array of Random Standard encoding for each row in categories\r\n",
        "        \r\n",
        "    #Return self, nothing else to do here\r\n",
        "    def fit( self, X, y=None ):\r\n",
        "      #identify categorical columns\r\n",
        "      #self.cat_cols=list(X.select_dtypes('O').columns)\r\n",
        "      #Get a list of all unique categorical values for each column\r\n",
        "      self.categories = [X[column].unique() for column in X[self.cat_cols]]\r\n",
        "      #replace missing values and append missing value label to each column to handle missing values in test dataset that might not be empty in train dataset\r\n",
        "      for i in range(len(self.categories)):\r\n",
        "        if np.array(self.categories[i].astype(str)!=str(np.nan)).all():\r\n",
        "          self.categories[i]=np.append(self.categories[i],np.nan)\r\n",
        "      #compute RandomStandardEncoding \r\n",
        "      self.RSE=[np.random.normal(0,1,len(self.categories[i])) for i in range(len(self.cat_cols))]\r\n",
        "      return self \r\n",
        "    \r\n",
        "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \r\n",
        "    def transform(self, X, y=None):\r\n",
        "      for i in range(len(self.cat_cols)):\r\n",
        "        #Temporary measure to handle previously unseen values\r\n",
        "        #replace unseen values with NaN\r\n",
        "        X.loc[X[~X[(str(self.cat_cols[i]))].isin(self.categories[i])].index,(str(self.cat_cols[i]))]=np.NaN\r\n",
        "\r\n",
        "        #replace seen values with encoding\r\n",
        "        X.loc[:,(str(self.cat_cols[i]))].replace(dict(zip(self.categories[i], self.RSE[i])),inplace=True)\r\n",
        "      return X    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r82JwegOLsja"
      },
      "source": [
        "class CustomStandardScaler(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,mean=None,var=None,n_samples_seen=None,scale=None):\n",
        "    self.mean=None #mean\n",
        "    self.var=None\n",
        "    self.n_samples_seen=None\n",
        "    self.scale=None\n",
        "\n",
        "  def compute_sample_mean(self,X):\n",
        "    return np.mean(X,axis=0)\n",
        "\n",
        "  def compute_sample_var(self,X):\n",
        "    return np.var(X,axis=0)\n",
        "\n",
        "  def compute_sample_size(self,X):\n",
        "    #assuming X is imputed, if there are null values, throw error aksing that X be imputed first\n",
        "    return len(X)\n",
        "\n",
        "  def compute_pooled_mean(self,X):\n",
        "    #compute the sample mean and size\n",
        "    sample_mean=self.compute_sample_mean(X)\n",
        "    sample_count=self.compute_sample_size(X) \n",
        "    #compute pool mean\n",
        "    pool_mean=(self.mean*self.n_samples_seen + sample_mean*sample_count)/(self.n_samples_seen + sample_count)\n",
        "\n",
        "    return pool_mean\n",
        "\n",
        "  def compute_pooled_var(self,X):\n",
        "    #compute the sample var and size\n",
        "    sample_var=self.compute_sample_var(X)\n",
        "    sample_count=self.compute_sample_size(X) \n",
        "    #compute pool variance\n",
        "    pool_var=(self.var*(self.n_samples_seen - 1) + sample_var*(sample_count - 1))/(self.n_samples_seen + sample_count - 2)\n",
        "\n",
        "    return pool_var\n",
        "\n",
        "  def fit(self,X):\n",
        "    if self.mean is None:\n",
        "      self.mean=self.compute_sample_mean(X)\n",
        "    else: \n",
        "      self.mean=self.compute_pooled_mean(X)\n",
        "    \n",
        "    if self.var is None:\n",
        "      self.var=self.compute_sample_var(X)\n",
        "    else: \n",
        "      self.var=self.compute_pooled_var(X)\n",
        "\n",
        "    if self.n_samples_seen is None:\n",
        "      self.n_samples_seen=self.compute_sample_size(X) \n",
        "    else: \n",
        "      self.n_samples_seen+=self.compute_sample_size(X)\n",
        "\n",
        "  def transform(self,X):\n",
        "    return (X-self.mean)/np.sqrt(self.var)\n",
        "\n",
        "  def inverse_transform(self,X):\n",
        "    return X*np.sqrt(self.var) + self.mean\n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To-l6iJ8Yssa"
      },
      "source": [
        "c_scaler=CustomStandardScaler()\n",
        "c_scaler.fit(fed1_arr)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZI84WTfgG5C"
      },
      "source": [
        "c_scaler.fit(fed2_arr)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6CAMkhfN2H",
        "outputId": "06aa840e-9f97-4062-fc97-e2545df97a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('mean: ',c_scaler.mean)\n",
        "print('var: ',c_scaler.var)\n",
        "print('n_samples: ',c_scaler.n_samples_seen)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean:  [1.65956641e+00 5.64872473e-01 3.72318372e-01 1.52552696e-01\n",
            " 1.11149718e-02 2.88552008e-01 2.73025404e-01 1.63905427e+00\n",
            " 1.14193745e+00 7.18051386e+00 1.06073344e+03 1.77432427e+02]\n",
            "var:  [2.56411923e+01 1.21196638e+01 7.62461704e-01 6.40281393e-01\n",
            " 3.13458405e-02 8.61782507e-01 8.69391342e-01 2.52004592e+01\n",
            " 2.74346269e-01 7.59405744e-01 1.76069479e+04 2.19590546e+07]\n",
            "n_samples:  256141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX-dybZroORT",
        "outputId": "85cb9102-f0f6-4bda-a77c-233252d45c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z=c_scaler.transform(fed12_arr)\n",
        "np.sum(fed12_arr-c_scaler.inverse_transform(z),axis=0)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.38200562e-12, -1.36779477e-13,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.91846539e-13,\n",
              "        0.00000000e+00, -9.76996262e-15, -1.70530257e-12,  1.18363985e-10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqD9-thaqR1X",
        "outputId": "9e66d0e4-fd57-4026-b225-45ada491b9d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.sum(z-d1d2_numscaler.transform(fed12_arr),axis=0)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-8.89399665e-13, -4.52160531e-12, -3.41437989e-12, -4.35831926e-12,\n",
              "       -2.35922393e-13,  1.69825265e-12,  2.38609132e-12,  5.37184186e-12,\n",
              "       -4.24965618e-12, -2.30082620e-12, -4.88693461e-12,  5.01965136e-12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D14nS8XjrDx_",
        "outputId": "abcd5548-a9f3-4b44-9991-4b7e269cb2d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "c_scaler.transform(fed2_arr)\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151197"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uT2HMiqfZbC",
        "outputId": "01c26a91-e5f6-4cdf-cce5-a1bcc253bb58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('mean: ',d1d2_numscaler.mean_)\n",
        "print('var: ',d1d2_numscaler.var_)\n",
        "print('n_samples: ',d1d2_numscaler.n_samples_seen_)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean:  [1.65956641e+00 5.64872473e-01 3.72318372e-01 1.52552696e-01\n",
            " 1.11149718e-02 2.88552008e-01 2.73025404e-01 1.63905427e+00\n",
            " 1.14193745e+00 7.18051386e+00 1.06073344e+03 1.77432427e+02]\n",
            "var:  [2.56622467e+01 1.21703331e+01 7.63296334e-01 6.40287980e-01\n",
            " 3.13474050e-02 8.62958765e-01 8.69566038e-01 2.52277475e+01\n",
            " 2.74379042e-01 7.64549919e-01 1.76283923e+04 2.19819023e+07]\n",
            "n_samples:  256141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6jvgrhMfzdZ",
        "outputId": "be466ce2-189c-49ad-b956-67645cb9c275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('mean difference: ',d1d2_numscaler.mean_ - c_scaler.mean)\n",
        "print('var difference: ',d1d2_numscaler.var_ - c_scaler.var)\n",
        "print('n_samples difference: ',d1d2_numscaler.n_samples_seen_ - c_scaler.n_samples_seen)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean difference:  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.52651283e-14]\n",
            "var difference:  [2.10544408e-02 5.06692761e-02 8.34629199e-04 6.58660272e-06\n",
            " 1.56454454e-06 1.17625763e-03 1.74695240e-04 2.72883905e-02\n",
            " 3.27728944e-05 5.14417441e-03 2.14444297e+01 2.28477565e+04]\n",
            "n_samples difference:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9otisY5U9i-"
      },
      "source": [
        "fe_cols=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/feature_engineering_columns.csv',header=None,squeeze=True)\r\n",
        "drop_cols=read_csv_to_list('https://github.com/sharsulkar/H1B_LCA_outcome_prediction/raw/main/data/processed/drop_columns.csv',header=None,squeeze=True)\r\n",
        "cat_cols=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/categorical_columns.csv',header=None,squeeze=True)\r\n",
        "num_cols=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/numeric_columns.csv',header=None,squeeze=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zdtF62nfVSR"
      },
      "source": [
        "#Build preprocessing pipeline\r\n",
        "build_feature_pipe=make_pipeline(\r\n",
        "    droprows_Transformer(),\r\n",
        "    buildfeatures_Transformer(fe_cols)\r\n",
        "    )\r\n",
        "\r\n",
        "numerical_preprocess=make_pipeline(\r\n",
        "    SimpleImputer(strategy='mean'),\r\n",
        "    StandardScaler()\r\n",
        ")\r\n",
        "preprocess_pipe=make_column_transformer(\r\n",
        "    (dropfeatures_Transformer(columns=drop_cols,inplace=True),drop_cols),\r\n",
        "    (RSE_Transformer(cat_cols),cat_cols),\r\n",
        "    (numerical_preprocess,num_cols),\r\n",
        "    remainder='passthrough'\r\n",
        ")\r\n",
        "all_preprocess=make_pipeline(\r\n",
        "    preprocess_pipe\r\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l0g-pcefMMR"
      },
      "source": [
        "#drop unneeded rows+build features\r\n",
        "fed1_df=build_feature_pipe.fit_transform(data1_df)\r\n",
        "fed2_df=build_feature_pipe.fit_transform(data2_df)\r\n",
        "fed12_df=build_feature_pipe.fit_transform(input_df)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9L7bLAjjbTO"
      },
      "source": [
        "#Instantiate imputer\r\n",
        "d1_impute=SimpleImputer(strategy='median',copy=False)\r\n",
        "d2_impute=SimpleImputer(strategy='median',copy=False)\r\n",
        "d1d2_impute=SimpleImputer(strategy='median',copy=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VfiQvroXOMP"
      },
      "source": [
        "#scaling numerical columns\r\n",
        "d1_numscaler=StandardScaler()\r\n",
        "d2_numscaler=StandardScaler()\r\n",
        "d1d2_numscaler=StandardScaler()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN2uMCzsjRE0"
      },
      "source": [
        "#Impute missing values\r\n",
        "fed1_arr=d1_impute.fit_transform(fed1_df[num_cols])\r\n",
        "fed2_arr=d2_impute.fit_transform(fed2_df[num_cols])\r\n",
        "fed12_arr=d1d2_impute.fit_transform(fed12_df[num_cols])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT709wWoe-z7",
        "outputId": "c1362c51-d445-48d1-c474-f0f47ee75542"
      },
      "source": [
        "#Fit scaler to get parameters\r\n",
        "d1_numscaler.fit(fed1_arr)\r\n",
        "d2_numscaler.fit(fed2_arr)\r\n",
        "d1d2_numscaler.fit(fed12_arr)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXmUPezBmBI8"
      },
      "source": [
        "new_mean=(mean1\\*N1 + mean2\\*N2)/(N1+N1)  \r\n",
        "https://www.statisticshowto.com/combined-mean/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdyzZ1_ajP4r",
        "outputId": "f60fc17f-a749-4912-8863-aa421702a405"
      },
      "source": [
        "#compute pooled mean of two separate datasets\r\n",
        "(d1_numscaler.mean_*d1_numscaler.n_samples_seen_+d2_numscaler.mean_*d2_numscaler.n_samples_seen_)/(d1_numscaler.n_samples_seen_+d2_numscaler.n_samples_seen_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.65956641e+00, 5.64872473e-01, 3.72318372e-01, 1.52552696e-01,\n",
              "       1.11149718e-02, 2.88552008e-01, 2.73025404e-01, 1.63905427e+00,\n",
              "       1.14193745e+00, 7.18051386e+00, 1.06073344e+03, 1.77432427e+02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCexO25rlyXl",
        "outputId": "d2808dbf-9054-4ffd-cabb-1397c9feaaf0"
      },
      "source": [
        "#compared to the mean of the combined datasets\r\n",
        "d1d2_numscaler.mean_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.65956641e+00, 5.64872473e-01, 3.72318372e-01, 1.52552696e-01,\n",
              "       1.11149718e-02, 2.88552008e-01, 2.73025404e-01, 1.63905427e+00,\n",
              "       1.14193745e+00, 7.18051386e+00, 1.06073344e+03, 1.77432427e+02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N90KpNFNmYC8",
        "outputId": "35615337-72f8-4ddc-a2eb-3bfda990e496"
      },
      "source": [
        "#compute pooled variance of two separate datasets\r\n",
        "d1d2_numscaler.var_-(d1_numscaler.var_*(d1_numscaler.n_samples_seen_-1)+d2_numscaler.var_*(d2_numscaler.n_samples_seen_-1))/(d1_numscaler.n_samples_seen_+d2_numscaler.n_samples_seen_-2)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.10544408e-02, 5.06692761e-02, 8.34629199e-04, 6.58660272e-06,\n",
              "       1.56454454e-06, 1.17625763e-03, 1.74695240e-04, 2.72883905e-02,\n",
              "       3.27728944e-05, 5.14417441e-03, 2.14444297e+01, 2.28477565e+04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYzYGLOWoxVo",
        "outputId": "b8b946cb-1910-4b8c-baf0-bfef2864ac0f"
      },
      "source": [
        "#compared to the variance of the combined datasets\r\n",
        "d1d2_numscaler.var_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.56622467e+01, 1.21703331e+01, 7.63296334e-01, 6.40287980e-01,\n",
              "       3.13474050e-02, 8.62958765e-01, 8.69566038e-01, 2.52277475e+01,\n",
              "       2.74379042e-01, 7.64549919e-01, 1.76283923e+04, 2.19819023e+07])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysZuCqoAtyNH"
      },
      "source": [
        "#Instantiate a standardscaler with the pooled mean and variance calcuated above\r\n",
        "d3_numscaler=StandardScaler()\r\n",
        "d3_numscaler.mean_=(d1_numscaler.mean_*d1_numscaler.n_samples_seen_+d2_numscaler.mean_*d2_numscaler.n_samples_seen_)/(d1_numscaler.n_samples_seen_+d2_numscaler.n_samples_seen_) #pooled mean\r\n",
        "d3_numscaler.var_=(d1_numscaler.var_*(d1_numscaler.n_samples_seen_-1)+d2_numscaler.var_*(d2_numscaler.n_samples_seen_-1))/(d1_numscaler.n_samples_seen_+d2_numscaler.n_samples_seen_-2) #pooled variance\r\n",
        "d3_numscaler.n_samples_seen_=d1_numscaler.n_samples_seen_+d2_numscaler.n_samples_seen_ #total number of samples\r\n",
        "d3_numscaler.scale_=np.sqrt(d3_numscaler.var_) #sqrt(var) according to the method"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpuKRVXGuEFv"
      },
      "source": [
        "#Scale the combined dataset using the new scaler and the combined scaler defined earlier\r\n",
        "d3_scaled=d3_numscaler.transform(fed12_arr)\r\n",
        "d1d2_scaled=d1d2_numscaler.transform(fed12_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdbTMVn1wW8o",
        "outputId": "8fcae5a0-6077-4624-d7c7-dfd181b52d62"
      },
      "source": [
        "#compare the difference between the transformed data of these 2 scalers, ideally all columns should have 0 difference\r\n",
        "#but looks like columns 7 (WORKSITE_WORKERS) and 8 (TOTAL_WORKSITE_LOCATIONS) have differences.\r\n",
        "np.sum(d1d2_scaled-d3_scaled,axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8.89399665e-13,  4.52160531e-12,  3.41437989e-12,  4.35831926e-12,\n",
              "        2.35922393e-13, -1.69825265e-12, -2.38609132e-12, -5.37184186e-12,\n",
              "        4.24965618e-12,  2.30082620e-12,  4.88693461e-12, -5.01965136e-12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gtRvdlOutTg",
        "outputId": "8ab5b5e2-ca64-41e3-d239-185256ec5365"
      },
      "source": [
        "#check the indexes where the difference in non-zero along the columns\r\n",
        "np.argwhere(np.floor(np.sum(d1d2_scaled-d3_scaled,axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   321],\n",
              "       [  1028],\n",
              "       [  1029],\n",
              "       ...,\n",
              "       [255881],\n",
              "       [256004],\n",
              "       [256111]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEP6EriCvnLt",
        "outputId": "7dc2d248-092a-432f-fc02-f33de9730d6b"
      },
      "source": [
        "#check a sample\r\n",
        "d1d2_scaled[321]-d3_scaled[321]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.34438295e-05,  3.38119407e-04, -3.93114960e-04,  9.80599544e-07,\n",
              "        1.56667952e-06,  2.11912095e-04,  2.94147881e-05,  6.88684730e-05,\n",
              "        1.61843142e-05,  4.56505871e-03, -1.57120356e-04, -2.32644563e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN9YeCrK2yFb",
        "outputId": "cd1b89e3-0f30-4d13-8f38-d5a4877cd674"
      },
      "source": [
        "#check difference between the data and its inverse transform\r\n",
        "np.sum(fed12_arr-d1d2_numscaler.inverse_transform(d3_scaled),axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.69968492e-11,  1.99740890e-10, -2.74292811e-11,  8.39245340e-13,\n",
              "       -4.24105195e-14, -6.27992103e-12, -7.39930339e-12,  1.62687641e-11,\n",
              "       -8.20465917e-12,  3.38216566e-10,  2.56568455e-09, -1.58673377e-08])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_miW1m9j30Xb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}