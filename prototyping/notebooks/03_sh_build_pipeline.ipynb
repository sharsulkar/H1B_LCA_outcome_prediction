{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_sh_build_pipeline.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/sharsulkar/H1B_LCA_outcome_prediction/blob/main/prototyping/notebooks/03_sh_build_pipeline.ipynb",
      "authorship_tag": "ABX9TyON9r5b6oc81eXhizJIyOQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharsulkar/H1B_LCA_outcome_prediction/blob/main/prototyping/notebooks/03_sh_build_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YrgVUbr6K4E"
      },
      "source": [
        "import numpy as np\r\n",
        "np.random.seed(42)\r\n",
        "import pandas as pd\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
        "from sklearn.compose import make_column_transformer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsw_aFax6iNW"
      },
      "source": [
        "observations_df=pd.read_csv('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/reports/final_observations.csv',sep='$',index_col=0,error_bad_lines=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-NkH9Sg7HJU"
      },
      "source": [
        "def read_csv_to_list(filepath,header=None,squeeze=True):\n",
        "  return list(pd.read_csv(filepath,header=None,squeeze=True))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfNo2_-X7IZS"
      },
      "source": [
        "#required_features=list(observations_df[(observations_df.preprocess_comment.isin([np.NaN,'Feature engineering','Target feature','Use feature as is'])) & (~observations_df.preprocess_action.isin(['New feature']))].index)\n",
        "required_features=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/required_features.csv',header=None,squeeze=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eI3vf7UL6UG"
      },
      "source": [
        "LCA_df=pd.read_excel('https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/LCA_Disclosure_Data_FY2020_Q1.xlsx',usecols=required_features)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYmwF1gIbLbS"
      },
      "source": [
        "LCA_dfcopy=LCA_df.copy()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxxjTn_dTj9q"
      },
      "source": [
        "#Custom transformer to drop rows based on filter\r\n",
        "class droprows_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, row_index, inplace, reset_index):\r\n",
        "      self.row_index = row_index # row index to drop\r\n",
        "      self.inplace=True\r\n",
        "      self.reset_index=True\r\n",
        "\r\n",
        "    def fit( self, X, y=None):\r\n",
        "      return self \r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "      X.drop(index=self.row_index,inplace=self.inplace)\r\n",
        "      if self.reset_index:\r\n",
        "        X.reset_index(inplace=True)\r\n",
        "      return X"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2x-ShLhVB_D"
      },
      "source": [
        "drop_row_index=LCA_df[~LCA_df.CASE_STATUS.isin(['Certified','Denied'])].index\r\n",
        "dr=droprows_Transformer(row_index=drop_row_index,inplace=True,reset_index=True)\r\n",
        "dr.transform(LCA_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gim2Nt4WClDL"
      },
      "source": [
        "#Separate target column\r\n",
        "y=LCA_df.pop('CASE_STATUS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ThgmRAHxDh"
      },
      "source": [
        "class buildfeatures_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "  def __init__(self, input_columns):\r\n",
        "    self.input_columns=input_columns\r\n",
        "\r\n",
        "  def date_diff(self,date1,date2):\r\n",
        "    return date1-date2\r\n",
        "\r\n",
        "  def is_USA(self,country):\r\n",
        "    if country=='UNITED STATES OF AMERICA':\r\n",
        "      USA_YN='Y' \r\n",
        "    else:\r\n",
        "      USA_YN='N'\r\n",
        "    return USA_YN\r\n",
        "\r\n",
        "  def fit(self, X, y=None):\r\n",
        "    return self\r\n",
        "\r\n",
        "  def transform(self, X, y=None):\r\n",
        "    # Processing_Days and Validity_days\r\n",
        "    X['PROCESSING_DAYS']=self.date_diff(X.DECISION_DATE, X.RECEIVED_DATE).dt.days\r\n",
        "    X['VALIDITY_DAYS']=self.date_diff(X.END_DATE, X.BEGIN_DATE).dt.days\r\n",
        "\r\n",
        "    # SOC_Codes\r\n",
        "    X['SOC_CD2']=X.SOC_CODE.str.split(pat='-',n=1,expand=True)[0]\r\n",
        "    X['SOC_CD4']=X.SOC_CODE.str.split(pat='-',n=1,expand=True)[1].str.split(pat='.',n=1,expand=True)[0]\r\n",
        "    X['SOC_CD_ONET']=X.SOC_CODE.str.split(pat='-',n=1,expand=True)[1].str.split(pat='.',n=1,expand=True)[1]\r\n",
        "\r\n",
        "    # USA_YN\r\n",
        "    X['USA_YN']=X.EMPLOYER_COUNTRY.apply(self.is_USA)\r\n",
        "\r\n",
        "    # Employer_Worksite_YN\r\n",
        "    X['EMPLOYER_WORKSITE_YN']='Y'\r\n",
        "    X.loc[X.EMPLOYER_POSTAL_CODE.ne(X.WORKSITE_POSTAL_CODE),'EMPLOYER_WORKSITE_YN']='N'\r\n",
        "\r\n",
        "    # OES_YN\r\n",
        "    X['OES_YN']='Y'\r\n",
        "    X.iloc[LCA_df[~X.PW_OTHER_SOURCE.isna()].index,X.columns.get_loc('OES_YN')]='N'\r\n",
        "\r\n",
        "    # SURVEY_YEAR\r\n",
        "    X['SURVEY_YEAR']=pd.to_datetime(X.PW_OES_YEAR.str.split(pat='-',n=1,expand=True)[0]).dt.to_period('Y')\r\n",
        "    PW_other_year=X[X.OES_YN=='N'].PW_OTHER_YEAR\r\n",
        "    #Rename the series and update dataframe with series object\r\n",
        "    PW_other_year.rename(\"SURVEY_YEAR\",inplace=True)\r\n",
        "    X.update(PW_other_year)\r\n",
        "\r\n",
        "    # WAGE_ABOVE_PREVAILING_HR\r\n",
        "    X['WAGE_PER_HR']=X.WAGE_RATE_OF_PAY_FROM\r\n",
        "    #compute for Year\r\n",
        "    X.iloc[X[X.WAGE_UNIT_OF_PAY=='Year'].index,X.columns.get_loc('WAGE_PER_HR')]=X[X.WAGE_UNIT_OF_PAY=='Year'].WAGE_RATE_OF_PAY_FROM/2067\r\n",
        "    #compute for Month\r\n",
        "    X.iloc[X[X.WAGE_UNIT_OF_PAY=='Month'].index,X.columns.get_loc('WAGE_PER_HR')]=X[X.WAGE_UNIT_OF_PAY=='Month'].WAGE_RATE_OF_PAY_FROM/172\r\n",
        "\r\n",
        "    #initialize with WAGE_RATE_OF_PAY_FROM\r\n",
        "    X['PW_WAGE_PER_HR']=X.PREVAILING_WAGE\r\n",
        "    #compute for Year\r\n",
        "    X.iloc[X[X.PW_UNIT_OF_PAY=='Year'].index,X.columns.get_loc('PW_WAGE_PER_HR')]=X[X.PW_UNIT_OF_PAY=='Year'].PREVAILING_WAGE/2067\r\n",
        "    #compute for Month\r\n",
        "    X.iloc[X[X.PW_UNIT_OF_PAY=='Month'].index,X.columns.get_loc('PW_WAGE_PER_HR')]=X[X.PW_UNIT_OF_PAY=='Month'].PREVAILING_WAGE/172\r\n",
        "\r\n",
        "    X['WAGE_ABOVE_PW_HR']=X.WAGE_PER_HR-X.PW_WAGE_PER_HR\r\n",
        "\r\n",
        "    return X"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10I2s5AX7PqM"
      },
      "source": [
        "#fe_cols=list(observations_df[(observations_df.preprocess_comment.isin(['Feature engineering'])) & (~observations_df.preprocess_action.isin(['New feature']))].index)\n",
        "fe_cols=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/feature_engineering_columns.csv',header=None,squeeze=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZwXVkfCLs-q"
      },
      "source": [
        "\r\n",
        "bf=buildfeatures_Transformer(fe_cols)\r\n",
        "fe_df=bf.transform(LCA_df)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQJbgtICTF50"
      },
      "source": [
        "#Custom transformer to drop features for input feature list\r\n",
        "class dropfeatures_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, columns, inplace):\r\n",
        "      self.columns = columns # list of categorical columns in input Dataframe\r\n",
        "      self.inplace=True\r\n",
        "\r\n",
        "    def fit( self, X, y=None):\r\n",
        "      return self \r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "      X.drop(columns=self.columns,inplace=self.inplace)\r\n",
        "      return X"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrkfCXM-7WmY"
      },
      "source": [
        "#drop_cols=set(LCA_df.columns.values)-set(observations_df[observations_df.preprocess_action.isin(['New feature','Use feature as is'])].index.values)\n",
        "drop_cols=read_csv_to_list('https://github.com/sharsulkar/H1B_LCA_outcome_prediction/raw/main/data/processed/drop_columns.csv',header=None,squeeze=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYANjxv0U38l"
      },
      "source": [
        "\r\n",
        "df=dropfeatures_Transformer(columns=list(drop_cols),inplace=True)\r\n",
        "df.transform(fe_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf6YKkdz6hbN"
      },
      "source": [
        "#Custom transformer to compute Random Standard encoding\r\n",
        "#add option to return ordered encoding, whether to include encoding for missing value or not\r\n",
        "class RSE_Transformer(BaseEstimator, TransformerMixin):\r\n",
        "    #Class Constructor\r\n",
        "    def __init__( self, cat_cols, categories=None, RSE=None ):\r\n",
        "        self.cat_cols = cat_cols # list of categorical columns in input Dataframe\r\n",
        "        self.categories = categories # Array of unique non-numeric values in each categorical column\r\n",
        "        self.RSE = RSE # Array of Random Standard encoding for each row in categories\r\n",
        "        \r\n",
        "    #Return self, nothing else to do here\r\n",
        "    def fit( self, X, y=None ):\r\n",
        "      #identify categorical columns\r\n",
        "      #self.cat_cols=list(X.select_dtypes('O').columns)\r\n",
        "      #Get a list of all unique categorical values for each column\r\n",
        "      self.categories = [X[column].unique() for column in X[self.cat_cols]]\r\n",
        "      #replace missing values and append missing value label to each column to handle missing values in test dataset that might not be empty in train dataset\r\n",
        "      for i in range(len(self.categories)):\r\n",
        "        if np.array(self.categories[i].astype(str)!=str(np.nan)).all():\r\n",
        "          self.categories[i]=np.append(self.categories[i],np.nan)\r\n",
        "      #compute RandomStandardEncoding \r\n",
        "      self.RSE=[np.random.normal(0,1,len(self.categories[i])) for i in range(len(self.cat_cols))]\r\n",
        "      return self \r\n",
        "    \r\n",
        "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \r\n",
        "    def transform(self, X, y=None):\r\n",
        "      for i in range(len(self.cat_cols)):\r\n",
        "        #X[str(self.cat_cols[i])].replace(dict(zip(self.categories[i], self.RSE[i])),inplace=True)\r\n",
        "        X.loc[:,(str(self.cat_cols[i]))].replace(dict(zip(self.categories[i], self.RSE[i])),inplace=True)\r\n",
        "      return X    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8MFtlbq7Zm9"
      },
      "source": [
        "#cat_cols=observations_df[(observations_df['Categorical class'].isin(['Categorical','Ordinal','Binary'])) & (observations_df.preprocess_action!='Drop column') & (observations_df.preprocess_comment!='Target feature')].index.values\n",
        "cat_cols=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/categorical_columns.csv',header=None,squeeze=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4noKmFDk6k4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "4f9df2f8-db32-42e7-90e0-7ed1282fe824"
      },
      "source": [
        "#embed categorical features\r\n",
        "\r\n",
        "#col_imputer=SimpleImputer(strategy='constant',fill_value='missing')\r\n",
        "rse=RSE_Transformer(cat_cols)\r\n",
        "rse.fit_transform(fe_df[cat_cols])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VISA_CLASS</th>\n",
              "      <th>SOC_TITLE</th>\n",
              "      <th>FULL_TIME_POSITION</th>\n",
              "      <th>EMPLOYER_NAME</th>\n",
              "      <th>NAICS_CODE</th>\n",
              "      <th>AGENT_REPRESENTING_EMPLOYER</th>\n",
              "      <th>SECONDARY_ENTITY</th>\n",
              "      <th>PW_WAGE_LEVEL</th>\n",
              "      <th>AGREE_TO_LC_STATEMENT</th>\n",
              "      <th>H-1B_DEPENDENT</th>\n",
              "      <th>WILLFUL_VIOLATOR</th>\n",
              "      <th>PUBLIC_DISCLOSURE</th>\n",
              "      <th>SOC_CD2</th>\n",
              "      <th>SOC_CD4</th>\n",
              "      <th>SOC_CD_ONET</th>\n",
              "      <th>USA_YN</th>\n",
              "      <th>EMPLOYER_WORKSITE_YN</th>\n",
              "      <th>OES_YN</th>\n",
              "      <th>SURVEY_YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.496714</td>\n",
              "      <td>-0.234137</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.522860</td>\n",
              "      <td>-0.544696</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>0.157694</td>\n",
              "      <td>-0.740182</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-1.007175</td>\n",
              "      <td>-1.127133</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.306679</td>\n",
              "      <td>-0.455009</td>\n",
              "      <td>-0.399553</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>-0.113820</td>\n",
              "      <td>0.038739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.496714</td>\n",
              "      <td>1.579213</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.420187</td>\n",
              "      <td>1.290511</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>-0.450123</td>\n",
              "      <td>-0.604702</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.949118</td>\n",
              "      <td>-1.127133</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.306679</td>\n",
              "      <td>1.086818</td>\n",
              "      <td>-0.399553</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>-0.113820</td>\n",
              "      <td>0.038739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.496714</td>\n",
              "      <td>0.767435</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.281785</td>\n",
              "      <td>0.147969</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>-0.450123</td>\n",
              "      <td>-0.604702</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.949118</td>\n",
              "      <td>-1.127133</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>0.494441</td>\n",
              "      <td>-0.445083</td>\n",
              "      <td>-0.399553</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>-0.113820</td>\n",
              "      <td>0.038739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.496714</td>\n",
              "      <td>1.579213</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-1.344451</td>\n",
              "      <td>0.147969</td>\n",
              "      <td>0.474042</td>\n",
              "      <td>-0.450123</td>\n",
              "      <td>-0.740182</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.949118</td>\n",
              "      <td>-1.127133</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.306679</td>\n",
              "      <td>1.086818</td>\n",
              "      <td>-0.399553</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>-0.113820</td>\n",
              "      <td>0.038739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.496714</td>\n",
              "      <td>-0.234137</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.918652</td>\n",
              "      <td>0.147969</td>\n",
              "      <td>0.474042</td>\n",
              "      <td>-0.450123</td>\n",
              "      <td>-0.604702</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.949118</td>\n",
              "      <td>-1.127133</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.306679</td>\n",
              "      <td>-0.455009</td>\n",
              "      <td>-0.399553</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>-0.113820</td>\n",
              "      <td>0.038739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104939</th>\n",
              "      <td>-0.138264</td>\n",
              "      <td>0.899600</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.263699</td>\n",
              "      <td>-0.005227</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>0.157694</td>\n",
              "      <td>-0.740182</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.679936</td>\n",
              "      <td>-1.354600</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.306679</td>\n",
              "      <td>-1.776299</td>\n",
              "      <td>0.945214</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>0.877135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104940</th>\n",
              "      <td>-0.138264</td>\n",
              "      <td>0.069802</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.224633</td>\n",
              "      <td>0.147969</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>0.157694</td>\n",
              "      <td>1.662871</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.679936</td>\n",
              "      <td>-1.354600</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.004689</td>\n",
              "      <td>-0.773276</td>\n",
              "      <td>0.945214</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>0.111221</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>0.877135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104941</th>\n",
              "      <td>-0.138264</td>\n",
              "      <td>0.747294</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.349258</td>\n",
              "      <td>-0.225113</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>0.157694</td>\n",
              "      <td>1.662871</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.679936</td>\n",
              "      <td>-1.354600</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>0.494441</td>\n",
              "      <td>-0.445083</td>\n",
              "      <td>0.945214</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>0.877135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104942</th>\n",
              "      <td>-0.138264</td>\n",
              "      <td>0.471468</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>0.104286</td>\n",
              "      <td>1.724418</td>\n",
              "      <td>0.474042</td>\n",
              "      <td>0.157694</td>\n",
              "      <td>1.662871</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.679936</td>\n",
              "      <td>-1.354600</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.004689</td>\n",
              "      <td>0.869397</td>\n",
              "      <td>0.945214</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>0.111221</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>0.877135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104943</th>\n",
              "      <td>-0.138264</td>\n",
              "      <td>0.633919</td>\n",
              "      <td>-0.445503</td>\n",
              "      <td>-0.224633</td>\n",
              "      <td>0.147969</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>0.157694</td>\n",
              "      <td>-0.740182</td>\n",
              "      <td>-0.073652</td>\n",
              "      <td>-0.679936</td>\n",
              "      <td>-1.354600</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>-1.306679</td>\n",
              "      <td>1.086818</td>\n",
              "      <td>0.945214</td>\n",
              "      <td>1.064276</td>\n",
              "      <td>1.570392</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>0.877135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104944 rows Ã— 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        VISA_CLASS  SOC_TITLE  ...    OES_YN  SURVEY_YEAR\n",
              "0         0.496714  -0.234137  ... -0.113820     0.038739\n",
              "1         0.496714   1.579213  ... -0.113820     0.038739\n",
              "2         0.496714   0.767435  ... -0.113820     0.038739\n",
              "3         0.496714   1.579213  ... -0.113820     0.038739\n",
              "4         0.496714  -0.234137  ... -0.113820     0.038739\n",
              "...            ...        ...  ...       ...          ...\n",
              "104939   -0.138264   0.899600  ...  0.071533     0.877135\n",
              "104940   -0.138264   0.069802  ...  0.071533     0.877135\n",
              "104941   -0.138264   0.747294  ...  0.071533     0.877135\n",
              "104942   -0.138264   0.471468  ...  0.071533     0.877135\n",
              "104943   -0.138264   0.633919  ...  0.071533     0.877135\n",
              "\n",
              "[104944 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2yBkPb87aVc"
      },
      "source": [
        "#num_cols=observations_df[(observations_df['Categorical class']=='Numerical') & (observations_df.preprocess_action!='Drop column')].index.values\n",
        "num_cols=read_csv_to_list('https://raw.githubusercontent.com/sharsulkar/H1B_LCA_outcome_prediction/main/data/processed/numeric_columns.csv',header=None,squeeze=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqQFtVGV6lcE"
      },
      "source": [
        "#scale numerical features\r\n",
        "\r\n",
        "num_imputer=SimpleImputer(strategy='mean')\r\n",
        "std=StandardScaler()\r\n",
        "X=std.fit_transform(fe_df[num_cols])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjc_8_BB_8pS"
      },
      "source": [
        "LCA_df=LCA_dfcopy.copy()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCKzp4f2pYD4"
      },
      "source": [
        "#Build preprocessing pipeline\r\n",
        "build_feature_pipe=make_pipeline(\r\n",
        "    droprows_Transformer(row_index=drop_row_index,inplace=True,reset_index=True),\r\n",
        "    buildfeatures_Transformer(fe_cols)\r\n",
        "    )\r\n",
        "\r\n",
        "numerical_preprocess=make_pipeline(\r\n",
        "    SimpleImputer(strategy='mean'),\r\n",
        "    StandardScaler()\r\n",
        ")\r\n",
        "preprocess_pipe=make_column_transformer(\r\n",
        "    (dropfeatures_Transformer(columns=drop_cols,inplace=True),drop_cols),\r\n",
        "    (RSE_Transformer(cat_cols),cat_cols),\r\n",
        "    (numerical_preprocess,num_cols),\r\n",
        "    remainder='passthrough'\r\n",
        ")\r\n",
        "all_preprocess=make_pipeline(\r\n",
        "    preprocess_pipe\r\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOHgZRlVd_LU"
      },
      "source": [
        "#apply pipeline\r\n",
        "#feature engineering + drop rows\r\n",
        "fe_df=build_feature_pipe.fit_transform(LCA_df)\r\n",
        "#Separate target column - add conditions to apply only on training dataset\r\n",
        "y=fe_df.pop('CASE_STATUS')\r\n",
        "#drop columns + encoding\r\n",
        "X=all_preprocess.fit_transform(fe_df)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycqo8PYXpcyI"
      },
      "source": [
        "#save transformed dataset and target\r\n",
        "final_cols=['VISA_CLASS', 'SOC_TITLE', 'FULL_TIME_POSITION',\r\n",
        "       'TOTAL_WORKER_POSITIONS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT',\r\n",
        "       'CHANGE_PREVIOUS_EMPLOYMENT', 'NEW_CONCURRENT_EMPLOYMENT',\r\n",
        "       'CHANGE_EMPLOYER', 'AMENDED_PETITION', 'EMPLOYER_NAME', 'NAICS_CODE',\r\n",
        "       'AGENT_REPRESENTING_EMPLOYER', 'WORKSITE_WORKERS', 'SECONDARY_ENTITY',\r\n",
        "       'PW_WAGE_LEVEL', 'TOTAL_WORKSITE_LOCATIONS', 'AGREE_TO_LC_STATEMENT',\r\n",
        "       'H-1B_DEPENDENT', 'WILLFUL_VIOLATOR', 'PUBLIC_DISCLOSURE',\r\n",
        "       'PROCESSING_DAYS', 'VALIDITY_DAYS', 'SOC_CD2', 'SOC_CD4', 'SOC_CD_ONET',\r\n",
        "       'USA_YN', 'EMPLOYER_WORKSITE_YN', 'OES_YN', 'SURVEY_YEAR',\r\n",
        "       'WAGE_ABOVE_PW_HR']\r\n",
        "pd.DataFrame(X,columns=final_cols).to_csv('/content/drive/MyDrive/Datasets/LCA_q1_processed.csv')\r\n",
        "pd.DataFrame(y,columns=['CASE_STATUS']).to_csv('/content/drive/MyDrive/Datasets/LCA_q1_expected.csv')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1abWSPwamx5e"
      },
      "source": [
        "from pickle import dump, load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83m194LNpml7"
      },
      "source": [
        "#save pipeline\r\n",
        "#reference - https://machinelearningmastery.com/how-to-save-and-load-models-and-data-preparation-in-scikit-learn-for-later-use/\r\n",
        "dump(all_preprocess,open('/content/drive/MyDrive/preprocess_pipe.pkl','wb'))\r\n",
        "#all_preprocess=load(open('/content/drive/MyDrive/preprocess_pipe.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeYZksaiO1AQ",
        "outputId": "387cd536-9e34-4df5-fceb-add3e210d723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104944, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}